# 📊🏠 Immo Eliza Data Visualization 🏠📊

## Project Overview
The **Immo Eliza Data Visualization** project aims to provide insightful analysis of real estate data through comprehensive data cleaning and visualization. This project will help users understand property trends, prices, and other key metrics using robust data analysis techniques.

## 🎯 Objectives 🎯

- **Data Cleaning**: Process and clean the real estate data to ensure its accuracy and reliability.
- **Data Analysis**: Perform in-depth exploratory data analysis to identify key trends and insights.
- **Data Visualization**: Create static visualizations to effectively communicate the data findings.

![Data Cleaning](https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExZHdyNTFyM2E5cXVoNnZrZXZtaTZydndiZjExb3U3c2o0MzlsMXZiaCZlcD12MV9naWZzX3NlYXJjaCZjdD1n/yimRGd4BkiOWkdUpDa/giphy.gif)

## ✨ Features ✨
- **Data Cleaning**: Remove duplicates, handle missing values, and correct inaccuracies in the dataset.
- **Descriptive Statistics**: Calculate and present key statistical measures of the dataset.
- **Correlation Analysis**: Identify and visualize relationships between different variables.
- **Visualization**: Create static plots and charts to present insights from the data.

![Data Cleaning](https://media0.giphy.com/media/SYLj7wRDOtYz6QiYl2/giphy.webp?cid=ecf05e47awfmrkp5l4djh4tk59u7p1953tuvdcw1z094nnrv&ep=v1_gifs_search&rid=giphy.webp&ct=g.gif)

## 🛠️ Tools and Technologies 🛠️
- **Programming Language**: Python
- **Data Analysis Libraries**: 
  - **NumPy**: For numerical operations
  - **Pandas**: For data manipulation and analysis
  - **SciPy**: For scientific computing and technical computing
  - **Matplotlib**: For creating static plots and charts
  - **Seaborn**: For statistical data visualization

![Data Cleaning](https://media.giphy.com/media/lOfOrezUUVNAhtGveA/giphy.gif?cid=790b7611kn7n5aabodipzvpzsfkful6tcrm666q9zdfb33j8&ep=v1_gifs_search&rid=giphy.gif&ct=g)

## 📅 Project Timeline 📅 

![Data Cleaning](https://media.giphy.com/media/1XdfVRTyn5d31Q1lG0/giphy.gif?cid=790b761131737kls6f2akbdzvjj8978vquqjz06pgvj93tnf&ep=v1_gifs_search&rid=giphy.gif&ct=g.gif)

### Day 1
- Initial setup and environment configuration
- Import and load the dataset
- Preliminary data inspection

### Day 2
- Data cleaning:
  - Remove duplicates
  - Handle missing values
  - Correct inaccuracies

### Day 3
- Data transformation:
  - Normalize and standardize data
  - Feature engineering (if applicable)

### Day 4
- Exploratory Data Analysis (EDA):
  - Descriptive statistics
  - Correlation analysis
  - Visualization of key metrics

### Day 5
- Further data visualization:
  - Create static plots and charts to visualize insights

### Day 6
- Final review:
  - Testing and validation
  - Documentation

### Day 7
- Prepare final visualizations and report

## 👥 Contributors 👥 

- Adrien Piette
- Alper Carpan
- Minh Dao

![Data Cleaning](https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExNmU4NzgzNnd3bGxzbTN0b2g3bmt6bmV4Y3BnOHN0dnBoZnU0em45NCZlcD12MV9naWZzX3NlYXJjaCZjdD1n/3oEjHV0z8S7WM4MwnK/giphy.gif)






